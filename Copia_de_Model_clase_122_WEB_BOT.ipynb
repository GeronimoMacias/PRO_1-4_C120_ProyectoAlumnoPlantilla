{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeronimoMacias/PRO_1-4_C120_ProyectoAlumnoPlantilla/blob/main/Copia_de_Model_clase_122_WEB_BOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "090erQmgjIWL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Cargar los datos de entrenamiento\n",
        "train_data = pd.read_csv(\"./static/assets/data_files/tweet_emotions.csv\")\n",
        "\n",
        "training_sentences = []\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "    sentence = train_data.loc[i, \"content\"]\n",
        "    training_sentences.append(sentence)\n",
        "\n",
        "# Tokenizaci√≥n\n",
        "vocab_size = 40000\n",
        "max_length = 100\n",
        "trunc_type = \"post\"\n",
        "padding_type = \"post\"\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "# Definir el modelo con la misma arquitectura utilizada para guardar los pesos\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 64, input_length=max_length))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Intentar cargar los pesos\n",
        "try:\n",
        "    model.load_weights(\"./static/assets/model_files/Tweet_Emotion.h5\")\n",
        "    print(\"Pesos del modelo cargados correctamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al cargar los pesos del modelo: {e}\")\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Definir el diccionario de URL de emociones\n",
        "emo_code_url = {\n",
        "    \"empty\": [0, \"./static/assets/emoticons/Empty.png\"],\n",
        "    \"sadness\": [1, \"./static/assets/emoticons/Sadness.png\"],\n",
        "    \"enthusiasm\": [2, \"./static/assets/emoticons/Enthusiastic.png\"],\n",
        "    \"neutral\": [3, \"./static/assets/emoticons/Neutral.png\"],\n",
        "    \"worry\": [4, \"./static/assets/emoticons/Worry.png\"],\n",
        "    \"surprise\": [5, \"./static/assets/emoticons/Surprise.png\"],\n",
        "    \"love\": [6, \"./static/assets/emoticons/Love.png\"],\n",
        "    \"fun\": [7, \"./static/assets/emoticons/Fun.png\"],\n",
        "    \"hate\": [8, \"./static/assets/emoticons/Hate.png\"],\n",
        "    \"happiness\": [9, \"./static/assets/emoticons/Happiness.png\"],\n",
        "    \"boredom\": [10, \"./static/assets/emoticons/Boredom.png\"],\n",
        "    \"relief\": [11, \"./static/assets/emoticons/Relief.png\"],\n",
        "    \"anger\": [12, \"./static/assets/emoticons/Anger.png\"],\n",
        "}\n",
        "\n",
        "def predict(text):\n",
        "    predicted_emotion = \"\"\n",
        "    predicted_emotion_img_url = \"\"\n",
        "\n",
        "    if text != \"\":\n",
        "        sentence = [text]\n",
        "        sequences = tokenizer.texts_to_sequences(sentence)\n",
        "        padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "        testing_padded = np.array(padded)\n",
        "        predicted_class_label = np.argmax(model.predict(testing_padded), axis=-1)\n",
        "\n",
        "        for key, value in emo_code_url.items():\n",
        "            if value[0] == predicted_class_label:\n",
        "                predicted_emotion_img_url = value[1]\n",
        "                predicted_emotion = key\n",
        "    return predicted_emotion, predicted_emotion_img_url\n",
        "\n",
        "def show_entry():\n",
        "    day_entry_list = pd.read_csv(\"./static/assets/data_files/data_entry.csv\")\n",
        "    day_entry_list = day_entry_list.iloc[::-1]\n",
        "\n",
        "    date1 = (day_entry_list['date'].values[0])\n",
        "    date2 = (day_entry_list['date'].values[1])\n",
        "    date3 = (day_entry_list['date'].values[2])\n",
        "    entry1 = day_entry_list['text'].values[0]\n",
        "    entry2 = day_entry_list['text'].values[1]\n",
        "    entry3 = day_entry_list['text'].values[2]\n",
        "    emotion1 = day_entry_list[\"emotion\"].values[0]\n",
        "    emotion2 = day_entry_list[\"emotion\"].values[1]\n",
        "    emotion3 = day_entry_list[\"emotion\"].values[2]\n",
        "\n",
        "    emotion_url_1 = \"\"\n",
        "    emotion_url_2 = \"\"\n",
        "    emotion_url_3 = \"\"\n",
        "\n",
        "    for key, value in emo_code_url.items():\n",
        "        if key == emotion1:\n",
        "            emotion_url_1 = value[1]\n",
        "        if key == emotion2:\n",
        "            emotion_url_2 = value[1]\n",
        "        if key == emotion3:\n",
        "            emotion_url_3 = value[1]\n",
        "\n",
        "    return [\n",
        "        {\n",
        "            \"date\": date1,\n",
        "            \"entry\": entry1,\n",
        "            \"emotion\": emotion1,\n",
        "            \"emotion_url\": emotion_url_1\n",
        "        },\n",
        "        {\n",
        "            \"date\": date2,\n",
        "            \"entry\": entry2,\n",
        "            \"emotion\": emotion2,\n",
        "            \"emotion_url\": emotion_url_2\n",
        "        },\n",
        "        {\n",
        "            \"date\": date3,\n",
        "            \"entry\": entry3,\n",
        "            \"emotion\": emotion3,\n",
        "            \"emotion_url\": emotion_url_3\n",
        "        }\n",
        "    ]\n"
      ]
    }
  ]
}